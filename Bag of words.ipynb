{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 2.906090\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.clock()\n",
    "import pandas as pd       \n",
    "data = pd.read_csv('D:\\ML\\mixData.csv')\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "st = EnglishStemmer()\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "def review_to_words( raw_review ):\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review, \"lxml\").get_text() \n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    # 4. Convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # 5. Remove stop words and tranform the words to their stem \n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    stem_words = []\n",
    "    num_meanWords = len(meaningful_words)\n",
    "    for i in xrange( 0, num_meanWords):\n",
    "        w = st.stem(meaningful_words[i])\n",
    "        stem_words.append(w)\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( stem_words )) \n",
    "    \n",
    "num_reviews = data[\"review\"].size\n",
    "\n",
    "\n",
    "clean_train_reviews = []\n",
    "for i in xrange( 0, num_reviews ):\n",
    "    clean_train_reviews.append( review_to_words( data[\"review\"][i] ) )\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the feature by using the bag of words (define number of feature at max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 0.097415\n",
      "(790L, 884L)\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "#build a vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "vectorizer = CountVectorizer(max_features = 884) \n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'abl', u'absolut', u'accept', u'access', u'accessori', u'accord', u'account', u'act', u'action', u'activ', u'actual', u'ad', u'add', u'addit', u'address', u'admit', u'advertis', u'advic', u'advis', u'agent', u'ago', u'agre', u'ahead', u'allow', u'almost', u'along', u'alreadi', u'also', u'although', u'alway', u'amaz', u'amazon', u'amount', u'anoth', u'answer', u'anymor', u'anyon', u'anyth', u'anyway', u'anywher', u'apolog', u'appar', u'appear', u'appli', u'approv', u'april', u'around', u'arriv', u'ask', u'assist', u'assum', u'assur', u'attach', u'attempt', u'august', u'author', u'autom', u'automat', u'avail', u'ave', u'avoid', u'aw', u'away', u'back', u'backord', u'bad', u'bait', u'balanc', u'bank', u'base', u'basic', u'batteri', u'becom', u'begin', u'behind', u'believ', u'benefit', u'best', u'better', u'bewar', u'beyond', u'big', u'bill', u'birthday', u'black', u'blame', u'book', u'bother', u'bottom', u'bought', u'box', u'brand', u'broken', u'bs', u'buck', u'bunch', u'busi', u'button', u'buy', u'buyer', u'ca', u'cabl', u'call', u'came', u'camera', u'cameron', u'can', u'cancel', u'cannot', u'canon', u'cant', u'card', u'care', u'carrier', u'cart', u'case', u'caus', u'cc', u'cd', u'cell', u'center', u'certain', u'certif', u'chanc', u'chang', u'charg', u'chat', u'cheap', u'cheaper', u'check', u'checkout', u'children', u'choos', u'chose', u'christma', u'cingular', u'claim', u'class', u'clear', u'click', u'close', u'coast', u'code', u'com', u'combin', u'come', u'comment', u'communic', u'compani', u'compar', u'compens', u'complain', u'complaint', u'complet', u'comput', u'concern', u'condit', u'confirm', u'consid', u'consum', u'contact', u'contain', u'continu', u'conveni', u'copi', u'corpor', u'correct', u'cost', u'could', u'count', u'countri', u'coupl', u'coupon', u'cours', u'cover', u'crap', u'credit', u'cs', u'csr', u'current', u'custom', u'cut', u'damag', u'date', u'day', u'deal', u'dealt', u'debit', u'dec', u'decemb', u'decept', u'decid', u'declin', u'deduct', u'defect', u'definit', u'delay', u'delet', u'deliv', u'deliveri', u'demand', u'deni', u'depart', u'describ', u'detail', u'didnt', u'differ', u'digit', u'direct', u'disappoint', u'discount', u'discov', u'disgust', u'dishonest', u'display', u'disput', u'dissatisfi', u'dollar', u'done', u'dont', u'door', u'doubl', u'doubt', u'drive', u'drop', u'due', u'dvd', u'earli', u'easi', u'ebay', u'edit', u'either', u'electron', u'elig', u'els', u'elsewher', u'email', u'end', u'english', u'enough', u'enter', u'entir', u'error', u'especi', u'estim', u'etail', u'etc', u'even', u'eventu', u'ever', u'everi', u'everyon', u'everyth', u'exact', u'exampl', u'except', u'excus', u'exist', u'expect', u'expens', u'experi', u'experienc', u'expir', u'explain', u'explan', u'extra', u'extrem', u'fact', u'fail', u'fair', u'fake', u'fals', u'famili', u'far', u'fast', u'father', u'fault', u'fax', u'feb', u'fedex', u'fee', u'feedback', u'feel', u'figur', u'file', u'fill', u'final', u'find', u'fine', u'first', u'five', u'fix', u'flash', u'follow', u'forc', u'form', u'forward', u'found', u'four', u'fraud', u'fraudul', u'free', u'friday', u'friend', u'front', u'frustrat', u'fulfil', u'full', u'fund', u'futur', u'game', u'gave', u'general', u'generat', u'get', u'gift', u'give', u'given', u'glove', u'go', u'goe', u'gone', u'good', u'googl', u'got', u'gotten', u'great', u'ground', u'guarante', u'guess', u'guy', u'half', u'hand', u'handl', u'happen', u'happi', u'hard', u'hassl', u'hear', u'heard', u'hell', u'help', u'high', u'higher', u'histori', u'hit', u'hold', u'holiday', u'home', u'honest', u'honor', u'hope', u'horribl', u'hour', u'hous', u'howev', u'hp', u'http', u'huge', u'idea', u'idiot', u'ignor', u'im', u'immedi', u'impress', u'includ', u'incompet', u'inconveni', u'incorrect', u'increas', u'inde', u'india', u'indic', u'info', u'inform', u'initi', u'inquir', u'inquiri', u'insid', u'instead', u'instruct', u'insult', u'intend', u'intent', u'interest', u'intern', u'internet', u'investig', u'invoic', u'involv', u'ipad', u'issu', u'item', u'januari', u'job', u'joke', u'juli', u'june', u'keep', u'kept', u'kind', u'kindl', u'knew', u'know', u'label', u'lack', u'ladder', u'laptop', u'larg', u'last', u'late', u'later', u'law', u'learn', u'least', u'leatherman', u'leav', u'left', u'len', u'less', u'let', u'letter', u'lie', u'life', u'light', u'like', u'limit', u'line', u'link', u'list', u'liter', u'littl', u'live', u'local', u'locat', u'lock', u'log', u'logitech', u'long', u'longer', u'look', u'lose', u'lost', u'lot', u'love', u'low', u'lower', u'loyal', u'luck', u'made', u'mail', u'major', u'make', u'manag', u'mani', u'manner', u'manufactur', u'march', u'market', u'marketplac', u'match', u'materi', u'matter', u'may', u'mayb', u'mb', u'mean', u'meant', u'media', u'member', u'membership', u'memori', u'mention', u'merchandis', u'merchant', u'mess', u'messag', u'method', u'might', u'min', u'mind', u'mine', u'minut', u'miss', u'mistak', u'model', u'monday', u'money', u'monitor', u'month', u'morn', u'mous', u'move', u'movi', u'much', u'multipl', u'must', u'mx', u'name', u'nd', u'near', u'need', u'needless', u'negat', u'never', u'new', u'newegg', u'next', u'nice', u'nightmar', u'non', u'normal', u'note', u'noth', u'notic', u'notif', u'notifi', u'nov', u'novemb', u'number', u'numer', u'obvious', u'oct', u'octob', u'offer', u'offic', u'often', u'oh', u'ok', u'old', u'one', u'onlin', u'open', u'opinion', u'option', u'order', u'origin', u'other', u'outsid', u'outsourc', u'overal', u'overnight', u'oversea', u'pack', u'packag', u'page', u'paid', u'pair', u'part', u'parti', u'partner', u'pass', u'password', u'past', u'pay', u'payment', u'peopl', u'perfect', u'person', u'phone', u'photo', u'pick', u'pictur', u'piec', u'piss', u'place', u'plan', u'player', u'pleas', u'plenti', u'plus', u'pm', u'point', u'polici', u'poor', u'posit', u'possibl', u'post', u'practic', u'pre', u'premium', u'prepar', u'present', u'pretti', u'previous', u'price', u'prime', u'print', u'printer', u'prior', u'probabl', u'problem', u'proceed', u'process', u'product', u'program', u'promis', u'promot', u'prompt', u'proper', u'protect', u'provid', u'purchas', u'push', u'put', u'qualifi', u'qualiti', u'question', u'quick', u'quit', u'rate', u'rather', u'rd', u'reach', u'read', u'readi', u'real', u'realiz', u'realli', u'reason', u'rebat', u'receipt', u'receiv', u'recent', u'reciev', u'recommend', u'record', u'refer', u'refund', u'refus', u'regard', u'regular', u'relat', u'releas', u'remov', u'reorder', u'rep', u'repeat', u'replac', u'repli', u'report', u'repres', u'reput', u'request', u'requir', u'research', u'resel', u'resellerr', u'resolut', u'resolv', u'respond', u'respons', u'rest', u'result', u'retail', u'return', u'review', u'revolut', u'ridicul', u'right', u'ring', u'rip', u'rude', u'ruin', u'run', u'said', u'sale', u'samsung', u'santa', u'saturday', u'save', u'saver', u'saw', u'say', u'scam', u'schedul', u'screen', u'screw', u'search', u'second', u'secur', u'see', u'seem', u'seen', u'select', u'sell', u'seller', u'send', u'sent', u'sept', u'serious', u'servic', u'set', u'sever', u'shame', u'ship', u'shipment', u'shipper', u'shop', u'shopper', u'short', u'show', u'shown', u'side', u'sign', u'similar', u'simpl', u'simpli', u'sinc', u'sit', u'site', u'situat', u'slow', u'small', u'softwar', u'sold', u'solv', u'someon', u'someth', u'sometim', u'somewher', u'son', u'soon', u'sooner', u'sorri', u'sound', u'sourc', u'speak', u'speaker', u'special', u'specialist', u'specif', u'spend', u'spent', u'spoke', u'sponsor', u'st', u'stand', u'standard', u'star', u'start', u'state', u'statement', u'status', u'stay', u'steal', u'stick', u'still', u'stock', u'stop', u'store', u'stori', u'stuff', u'stupid', u'submit', u'subscrib', u'suck', u'suggest', u'super', u'supervisor', u'suppli', u'supplier', u'support', u'suppos', u'sure', u'surpris', u'switch', u'system', u'tablet', u'tactic', u'take', u'taken', u'talk', u'target', u'tax', u'team', u'telephon', u'televis', u'tell', u'term', u'terribl', u'th', u'thank', u'therefor', u'thing', u'think', u'third', u'though', u'thought', u'thousand', u'three', u'till', u'time', u'today', u'told', u'took', u'tool', u'top', u'total', u'track', u'trade', u'transact', u'transfer', u'transit', u'treat', u'tri', u'troubl', u'truck', u'true', u'trust', u'turn', u'tv', u'twice', u'two', u'type', u'typic', u'unabl', u'unaccept', u'understand', u'unfortun', u'unhappi', u'unit', u'unless', u'up', u'updat', u'upgrad', u'upon', u'upset', u'us', u'use', u'useless', u'usp', u'usual', u'valid', u'valu', u'vendor', u'verifi', u'via', u'video', u'visa', u'visit', u'wait', u'want', u'warehous', u'warn', u'warranti', u'wast', u'watch', u'way', u'web', u'webcam', u'websit', u'wednesday', u'week', u'weekend', u'well', u'went', u'whatev', u'white', u'whole', u'wife', u'will', u'wireless', u'wish', u'within', u'without', u'wonder', u'word', u'work', u'world', u'worri', u'wors', u'worst', u'worth', u'would', u'write', u'wrong', u'wrote', u'wtf', u'www', u'xmas', u'year', u'yes', u'yet']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790L,) Counter({0L: 720, 1L: 70})\n",
      "(790L, 884L)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "y = data.values[:, -1]\n",
    "print y.shape, Counter(y.tolist())\n",
    "x = train_data_features\n",
    "print x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (use Sigmoid function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 7.066550\n",
      "The training error is 0.000844\n",
      "The testing error is 0.011392\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "training_step = 100\n",
    "X = train_data_features\n",
    "Xnew = X.astype(None).reshape(X.shape)   #Change to non-type\n",
    "Y = np.array(data['class'])\n",
    "n_sample = len(Y)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n",
    "x = T.matrix('x')\n",
    "y = T.vector('y')\n",
    "w = theano.shared(np.zeros(n_features),name = 'w')    #Start at zero vector\n",
    "b = theano.shared(0.,name = 'b')\n",
    "\n",
    "#print('Initial model:')\n",
    "#print(w.get_value(), b.get_value())\n",
    "\n",
    "prob_y_x = 1/(1+T.exp(-T.dot(x,w)-b))\n",
    "prediction = prob_y_x > 0.5\n",
    "logli = T.sum(y*T.log(prob_y_x) + (1-y)*T.log(1-prob_y_x))\n",
    "cost_function = -(logli)\n",
    "gw , gb = T.grad(cost_function,[w,b])\n",
    "\n",
    "\n",
    "train_model = theano.function(\n",
    "                        inputs = [x,y], \n",
    "                        updates = [(w, w-0.1*gw), (b, b-0.1*gb)])\n",
    "predict = theano.function(inputs = [x], outputs = prediction)\n",
    "\n",
    "\n",
    "testing_errors =[]\n",
    "training_errors =[]\n",
    "kf = KFold(790, n_folds=10)\n",
    "for train, test in kf:\n",
    "    ytrain = Y[train]\n",
    "    xtrain = Xnew[train]\n",
    "    ytest = Y[test]\n",
    "    xtest = Xnew[test]\n",
    "    for i in range(training_step):\n",
    "        train_model(xtrain,ytrain)\n",
    "    ytrain_predict = np.array(predict(xtrain))\n",
    "    ytest_predict = np.array(predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 0.371844\n",
      "The training error is 0.167089\n",
      "The testing error is 0.173418\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "import numpy as np\n",
    "\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = BernoulliNB()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 0.188142\n",
      "The training error is 0.035724\n",
      "The testing error is 0.068354\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "import numpy as np\n",
    "\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = MultinomialNB()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 2.941601\n",
      "The training error is 0.088608\n",
      "The testing error is 0.088608\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn import svm\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = svm.SVC()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 11.363228\n",
      "The training error is 0.071449\n",
      "The testing error is 0.174684\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 12.310483\n",
      "The training error is 0.051617\n",
      "The testing error is 0.136709\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = KNeighborsClassifier(n_neighbors=4)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The computational time is 14.513743\n",
      "The training error is 0.094233\n",
      "The testing error is 0.191139\n"
     ]
    }
   ],
   "source": [
    "time_start = time.clock()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "testing_errors = []\n",
    "training_errors = []\n",
    "kf = KFold(790, n_folds=10, shuffle=True)\n",
    "for train, test in kf:\n",
    "    ytrain = data['class'][train]\n",
    "    xtrain = train_data_features[train]\n",
    "    ytest = data['class'][test]\n",
    "    xtest = train_data_features[test]\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ytrain_predict = np.array(model.predict(xtrain))\n",
    "    ytest_predict = np.array(model.predict(xtest))\n",
    "    testing_errors.append(1 - metrics.accuracy_score(ytest,ytest_predict))\n",
    "    training_errors.append(1 - metrics.accuracy_score(ytrain,ytrain_predict))\n",
    "    \n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print (\"The computational time is %f\") % time_elapsed\n",
    "\n",
    "print ('The training error is %f'  % np.average(training_errors))\n",
    "\n",
    "print ('The testing error is %f' % np.average(testing_errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
